# ğŸ“– LOLQA Project - Complete Summary

## ğŸ¯ Project Overview

**LOLQA** (League of Legends Q&A) is an intelligent chatbot application that answers questions about League of Legends using **Retrieval-Augmented Generation (RAG)** with LangChain, LangGraph, and OpenAI.

### Key Capabilities
- âœ… Answer questions about 172 League of Legends champions
- âœ… Count and list champions (with role filtering)
- âœ… Provide detailed information about abilities, skins, stats, lore
- âœ… Remember conversation context
- âœ… Use **tool calling** to intelligently decide how to answer questions
- âœ… Retrieve information **ONLY** from the knowledge base (no hallucination)

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                           â”‚
â”‚                      (Streamlit - app.py)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LANGGRAPH WORKFLOW                             â”‚
â”‚              (langgraph_workflow.py)                             â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Extract    â”‚â”€â”€â–¶â”‚   Retrieve   â”‚â”€â”€â–¶â”‚   Generate   â”‚        â”‚
â”‚  â”‚   Question   â”‚   â”‚   Context    â”‚   â”‚   Answer     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RAG SYSTEM                                  â”‚
â”‚                   (rag_system.py)                                â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              LLM WITH TOOLS (ReAct Pattern)            â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚
â”‚  â”‚  â”‚   search_    â”‚  â”‚    count_    â”‚  â”‚     list_    â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  champion_   â”‚  â”‚  champions   â”‚  â”‚  champions   â”‚ â”‚     â”‚
â”‚  â”‚  â”‚    info      â”‚  â”‚              â”‚  â”‚              â”‚ â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚     â”‚
â”‚  â”‚  â”‚get_database_ â”‚                                      â”‚     â”‚
â”‚  â”‚  â”‚    info      â”‚                                      â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            VECTOR STORE (ChromaDB)                     â”‚     â”‚
â”‚  â”‚        711 chunks for 172 champions                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA COLLECTION                                â”‚
â”‚                 (data_collector.py)                              â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Data Dragon  â”‚  â”‚ Web Scraper  â”‚  â”‚ Sample Data  â”‚          â”‚
â”‚  â”‚   Collector  â”‚  â”‚  Collector   â”‚  â”‚  Collector   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Data Flow

### 1. **Initialization Phase** (App Startup)

```
Start App
   â”‚
   â”œâ”€â–¶ Load Environment Variables (.env)
   â”‚
   â”œâ”€â–¶ Initialize Data Collectors
   â”‚   â””â”€â–¶ Data Dragon API (Riot Games)
   â”‚   â””â”€â–¶ Web Scraper (League Wiki)
   â”‚   â””â”€â–¶ Sample Data (Fallback)
   â”‚
   â”œâ”€â–¶ Collect Documents (172 champions)
   â”‚
   â”œâ”€â–¶ Create Embeddings (OpenAI text-embedding-3-small)
   â”‚
   â”œâ”€â–¶ Store in Vector Database (ChromaDB)
   â”‚   â””â”€â–¶ 711 chunks after text splitting
   â”‚
   â””â”€â–¶ Initialize RAG System with Tools
       â””â”€â–¶ search_champion_info
       â””â”€â–¶ count_champions
       â””â”€â–¶ list_champions
       â””â”€â–¶ get_database_info
```

### 2. **Query Processing Phase** (User Asks a Question)

```
User Input: "how many champions in lol?"
   â”‚
   â”œâ”€â–¶ Streamlit UI (app.py)
   â”‚   â””â”€â–¶ Store in session history
   â”‚
   â”œâ”€â–¶ LangGraph Workflow (langgraph_workflow.py)
   â”‚   â”œâ”€â–¶ Extract Question
   â”‚   â”œâ”€â–¶ Format Conversation History
   â”‚   â””â”€â–¶ Generate Answer
   â”‚
   â”œâ”€â–¶ RAG System (rag_system.py)
   â”‚   â”‚
   â”‚   â”œâ”€â–¶ LLM with Tools receives question
   â”‚   â”‚   â””â”€â–¶ Decides which tool to use
   â”‚   â”‚
   â”‚   â”œâ”€â–¶ Execute Tool Call
   â”‚   â”‚   â””â”€â–¶ count_champions()
   â”‚   â”‚       â””â”€â–¶ Query ChromaDB with filter: type="champion"
   â”‚   â”‚       â””â”€â–¶ Count unique champion names
   â”‚   â”‚       â””â”€â–¶ Return: "There are 172 champions in League of Legends"
   â”‚   â”‚
   â”‚   â””â”€â–¶ LLM generates final answer using tool result
   â”‚
   â””â”€â–¶ Return Answer to User
       â””â”€â–¶ Display in Streamlit UI
```

---

## ğŸ“ Project Structure

```
LOLQA/
â”‚
â”œâ”€â”€ ğŸ¨ FRONTEND
â”‚   â””â”€â”€ app.py                          # Streamlit UI
â”‚
â”œâ”€â”€ ğŸ§  CORE LOGIC
â”‚   â”œâ”€â”€ rag_system.py                   # RAG + Tool Calling
â”‚   â”œâ”€â”€ langgraph_workflow.py           # Workflow Orchestration
â”‚   â”œâ”€â”€ config.py                       # Configuration
â”‚   â”œâ”€â”€ constants.py                    # Prompt Templates & Messages
â”‚   â””â”€â”€ utils.py                        # Helper Functions
â”‚
â”œâ”€â”€ ğŸ“Š DATA COLLECTION
â”‚   â”œâ”€â”€ data_collector.py               # Main Collector Orchestrator
â”‚   â””â”€â”€ data_sources/
â”‚       â”œâ”€â”€ base_collector.py           # Base Class
â”‚       â”œâ”€â”€ data_dragon_collector.py    # Riot Data Dragon API
â”‚       â”œâ”€â”€ web_scraper_collector.py    # Wiki Scraper
â”‚       â”œâ”€â”€ riot_api_collector.py       # Riot Games API
â”‚       â””â”€â”€ sample_data_collector.py    # Fallback Data
â”‚
â”œâ”€â”€ ğŸ’¾ DATABASE
â”‚   â””â”€â”€ chroma_db/                      # Vector Store (711 chunks)
â”‚
â”œâ”€â”€ ğŸ“ DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                       # Quick Start Guide
â”‚   â”œâ”€â”€ PROJECT_ARCHITECTURE.md         # Detailed Architecture
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md              # This File
â”‚   â”œâ”€â”€ API_KEYS_SETUP.md              # API Keys Guide
â”‚   â”œâ”€â”€ DATA_COLLECTION.md             # Data Collection Details
â”‚   â””â”€â”€ QUICKSTART.md                  # Quick Setup
â”‚
â”œâ”€â”€ ğŸ³ DEPLOYMENT
â”‚   â”œâ”€â”€ Dockerfile                      # Docker Config
â”‚   â”œâ”€â”€ Procfile                        # Heroku/Railway
â”‚   â”œâ”€â”€ render.yaml                     # Render Config
â”‚   â””â”€â”€ setup.sh                        # Setup Script
â”‚
â””â”€â”€ ğŸ“¦ DEPENDENCIES
    â”œâ”€â”€ requirements.txt                # Python Packages
    â”œâ”€â”€ .env                           # Environment Variables
    â””â”€â”€ venv/                          # Virtual Environment
```

---

## ğŸ”§ Key Components Explained

### 1. **app.py** - Streamlit UI
- **Purpose**: Web interface for user interaction
- **Key Functions**:
  - `initialize_systems()`: Cached initialization of RAG + LangGraph
  - `process_query()`: Sends queries to LangGraph workflow
  - `handle_user_input()`: Manages conversation history
  - `render_sidebar()`: Shows example questions and copy button
- **Session State**:
  - `SESSION_MESSAGES`: Stores conversation history
  - Each message: `{"role": "user"/"assistant", "content": "..."}`

### 2. **rag_system.py** - RAG System with Tool Calling
- **Purpose**: Core intelligence - retrieves data and generates answers
- **Key Components**:
  
  **A. LLM with Tools (OpenAI Function Calling)**
  - `llm_with_tools`: GPT-4o-mini bound with 4 tools
  
  **B. Tools** (ReAct Pattern):
  1. **`search_champion_info(query)`**
     - Semantic search in vector store
     - Used for: "Who is Yasuo?", "What are Ahri's abilities?"
  
  2. **`count_champions(role_filter="")`**
     - Counts unique champions from metadata
     - Used for: "How many champions?", "How many mage champions?"
  
  3. **`list_champions(role_filter="", limit=20)`**
     - Lists champion names
     - Used for: "Give me all champion names"
  
  4. **`get_database_info()`**
     - Returns database version info
     - Used for: "When was data updated?"
  
  **C. Query Method**:
  ```python
  def query(question, chat_history):
      1. LLM receives question + tool descriptions
      2. LLM decides which tool(s) to call
      3. Execute tool calls
      4. LLM generates final answer using tool results
      5. Return answer
  ```

### 3. **langgraph_workflow.py** - Workflow Orchestration
- **Purpose**: Manages the flow of question â†’ answer
- **GraphState**: Tracks conversation state
  ```python
  {
      "question": str,
      "context": str,
      "answer": str,
      "messages": List[HumanMessage, AIMessage]
  }
  ```
- **Workflow Steps**:
  1. `_extract_question`: Extracts user question from state
  2. `_generate_answer`: Calls RAG system with conversation history
  3. `_format_response`: Formats the final answer

### 4. **data_collector.py** - Data Aggregation
- **Purpose**: Collects League of Legends data from multiple sources
- **Collectors**:
  - **DataDragonCollector**: Riot's static data API (172 champions)
  - **WebScraperCollector**: Scrapes League wiki for lore
  - **SampleDataCollector**: Fallback if APIs fail
- **Output**: 181 documents (172 champions + 9 other docs)

### 5. **data_sources/** - Individual Collectors
Each collector inherits from `BaseDataCollector`:
- **DataDragonCollector**: 
  - Fetches from `https://ddragon.leagueoflegends.com`
  - Version: 15.24.1
  - Includes: abilities, stats, skins, lore, tips
- **WebScraperCollector**: 
  - Scrapes League of Legends wiki
  - Extracts lore and game mechanics
- **RiotAPICollector**: 
  - Requires API key (not used by default)
  - For live match data

### 6. **Vector Store (ChromaDB)**
- **Storage**: `chroma_db/` directory
- **Embeddings**: OpenAI `text-embedding-3-small`
- **Data**:
  - 172 unique champions
  - 711 document chunks (after text splitting)
  - Metadata: `{type, champion, role, source}`
- **Retrieval**: Similarity search with k=3 default

---

## ğŸ¨ Technologies & Stack

### Core Framework
| Technology | Version | Purpose |
|------------|---------|---------|
| **LangChain** | 1.1.3 | RAG framework, LLM integration |
| **LangGraph** | 1.0.0+ | Workflow orchestration, state management |
| **LangSmith** | 0.1.0+ | Monitoring, tracing, debugging |

### LLM & Embeddings
| Technology | Model | Purpose |
|------------|-------|---------|
| **OpenAI** | gpt-4o-mini | Answer generation, tool calling |
| **OpenAI Embeddings** | text-embedding-3-small | Document embeddings |

### Data Storage
| Technology | Version | Purpose |
|------------|---------|---------|
| **ChromaDB** | 0.5.0+ | Vector database |
| **Python Dictionaries** | - | Session state management |

### Web Framework
| Technology | Version | Purpose |
|------------|---------|---------|
| **Streamlit** | 1.39.0+ | Web UI, user interface |

### Data Collection
| Technology | Version | Purpose |
|------------|---------|---------|
| **Requests** | 2.31.0+ | HTTP requests to APIs |
| **BeautifulSoup4** | 4.12.2+ | Web scraping |
| **lxml** | 5.1.0+ | HTML/XML parsing |

### Utilities
| Technology | Version | Purpose |
|------------|---------|---------|
| **python-dotenv** | 1.0.0+ | Environment variable management |
| **tiktoken** | 0.8.0+ | Token counting |
| **pydantic** | 2.9.0+ | Data validation |

---

## ğŸš€ How It Works - Step by Step

### Scenario: User asks "how many champions in lol?"

1. **User Input** (app.py)
   ```python
   user_question = "how many champions in lol?"
   st.session_state[SESSION_MESSAGES].append({
       "role": "user",
       "content": user_question
   })
   ```

2. **Send to Workflow** (app.py â†’ langgraph_workflow.py)
   ```python
   response = process_query(
       question=user_question,
       graph=workflow,
       conversation_history=previous_messages
   )
   ```

3. **Extract Question** (langgraph_workflow.py)
   ```python
   # GraphState updated with question
   state["question"] = "how many champions in lol?"
   ```

4. **Generate Answer** (langgraph_workflow.py â†’ rag_system.py)
   ```python
   answer = rag_system.query(
       question="how many champions in lol?",
       chat_history=formatted_history
   )
   ```

5. **LLM with Tools** (rag_system.py)
   ```python
   # LLM receives prompt with tools
   prompt = """You have access to tools...
   Question: how many champions in lol?"""
   
   # LLM decides: "I should use count_champions tool"
   tool_calls = [
       {
           "name": "count_champions",
           "args": {}
       }
   ]
   ```

6. **Execute Tool** (rag_system.py)
   ```python
   def count_champions(role_filter=""):
       results = vectorstore.get(
           where={"type": "champion"},
           limit=2000
       )
       unique_champions = set()
       for metadata in results['metadatas']:
           unique_champions.add(metadata['champion'])
       
       return f"There are {len(unique_champions)} champions"
   
   # Result: "There are 172 champions in League of Legends."
   ```

7. **Generate Final Answer** (rag_system.py)
   ```python
   # LLM receives tool result
   final_prompt = """Tool Results:
   count_champions: There are 172 champions in League of Legends.
   
   Question: how many champions in lol?
   
   Answer based ONLY on tool results."""
   
   # LLM generates: "There are 172 champions in League of Legends."
   ```

8. **Return to User** (langgraph_workflow.py â†’ app.py)
   ```python
   st.session_state[SESSION_MESSAGES].append({
       "role": "assistant",
       "content": "There are 172 champions in League of Legends."
   })
   st.chat_message("assistant").write(answer)
   ```

---

## ğŸ¯ Key Features

### 1. **Intelligent Tool Calling (ReAct Pattern)**
- LLM automatically decides which tool to use
- No hardcoded query patterns
- Truly general solution

**Example Flow**:
```
Q: "how many mage champions?"
   â””â”€â–¶ LLM thinks: "This is a counting question with a filter"
   â””â”€â–¶ Calls: count_champions(role_filter="Mage")
   â””â”€â–¶ Returns: "There are X mage champions"
```

### 2. **Conversation Memory**
- Remembers previous messages in session
- Formats history for LLM context
- Enables follow-up questions

**Example**:
```
[1] USER: "who is yasuo?"
[2] ASSISTANT: "Yasuo is a skilled swordsman..."
[3] USER: "how many skins does he have?"  # "he" = Yasuo
[2] ASSISTANT: "Yasuo has 15 skins..."     # Remembers context
```

### 3. **Hallucination Prevention**
- Strict prompts: "ONLY use tool results"
- "NEVER use training data"
- "Say 'I don't have that information' if not in context"

### 4. **Live Data**
- Data from Riot's Data Dragon API v15.24.1
- All 172 current champions
- Regularly updatable

### 5. **Copy Conversation Feature**
- Button in sidebar to copy entire chat
- Formatted as: `[1] USER: ... [2] ASSISTANT: ...`
- Useful for debugging and sharing

---

## ğŸ” Environment Setup

### Required API Keys

1. **OpenAI API Key** (Required)
   - Used for: Embeddings + LLM
   - Get from: https://platform.openai.com/api-keys
   
2. **LangSmith API Key** (Optional)
   - Used for: Monitoring and tracing
   - Get from: https://smith.langchain.com

### `.env` File
```env
OPENAI_API_KEY=sk-proj-...
LANGSMITH_API_KEY=lsv2_pt_...
LANGSMITH_PROJECT=lolqa
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_TRACING=true
```

---

## ğŸ› Recent Fixes & Improvements

### 1. **Context Memory Bug** âœ…
- **Problem**: Agent didn't remember previous messages
- **Solution**: 
  - Added `chat_history` parameter to RAG system
  - Updated prompt template to include conversation history
  - Modified LangGraph workflow to pass history

### 2. **Hallucination Issue** âœ…
- **Problem**: Agent mentioned "October 2023" training data
- **Solution**:
  - Strengthened prompt with "CRITICAL INSTRUCTIONS"
  - Added `get_database_info()` tool
  - Explicit rules against mentioning training cutoff

### 3. **Champion Count Bug** âœ…
- **Problem**: Showed 121 champions instead of 172
- **Solution**:
  - Database had all 172 champions (711 chunks)
  - Increased vectorstore.get() limit from 500 â†’ 2000
  - Now correctly counts all unique champions

### 4. **Tool Calling Implementation** âœ…
- **Problem**: Manual query classification was too rigid
- **Solution**:
  - Implemented ReAct pattern with OpenAI function calling
  - LLM decides which tools to use
  - Truly general, extensible solution

---

## ğŸ“Š Performance & Scalability

### Current Capacity
- **Champions**: 172 (all current LoL champions)
- **Documents**: 181 raw documents
- **Chunks**: 711 vector store chunks
- **Retrieval Speed**: ~1-2 seconds per query
- **Concurrent Users**: Limited by Streamlit free tier

### Optimization Opportunities
1. **Caching**: Cache frequent queries
2. **Batch Processing**: Process multiple tool calls in parallel
3. **Streaming**: Stream LLM responses for better UX
4. **Redis**: Add Redis for session management at scale

---

## ğŸš€ Deployment Options

### 1. **Local Development**
```bash
streamlit run app.py
```
Access at: `http://localhost:8501`

### 2. **Docker**
```bash
docker build -t lolqa .
docker run -p 8501:8501 --env-file .env lolqa
```

### 3. **Cloud Platforms**
- **Streamlit Cloud**: Easiest for Streamlit apps
- **Railway**: One-click deployment
- **Render**: Good for production
- **Heroku**: Enterprise-grade

---

## ğŸ“ Learning Resources

### Key Concepts to Understand

1. **RAG (Retrieval-Augmented Generation)**
   - Combines retrieval with generation
   - Grounds LLM responses in facts
   - Prevents hallucination

2. **Vector Embeddings**
   - Convert text to numerical vectors
   - Enable semantic similarity search
   - More powerful than keyword search

3. **LangChain Expression Language (LCEL)**
   - Chain components with `|` operator
   - Example: `retriever | prompt | llm | parser`

4. **LangGraph**
   - State machines for workflows
   - Manage conversation state
   - Orchestrate complex flows

5. **Tool Calling (Function Calling)**
   - LLM decides which functions to call
   - Structured output from LLM
   - ReAct pattern: Reason + Act

---

## ğŸ”® Future Enhancements

### Possible Improvements
1. âœ¨ **Multi-turn conversations** with memory persistence
2. âœ¨ **Image generation** for champion builds
3. âœ¨ **Voice input/output** for hands-free interaction
4. âœ¨ **Champion comparison** tool
5. âœ¨ **Real-time match data** integration
6. âœ¨ **Build recommendations** based on enemy comp
7. âœ¨ **Patch notes** summarization
8. âœ¨ **Multiple languages** support

---

## ğŸ“ Support & Contribution

### Getting Help
- ğŸ“– Read the docs in the project root
- ğŸ› Open an issue on GitHub
- ğŸ’¬ Check existing issues for solutions

### Contributing
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

---

## ğŸ“ Quick Reference Commands

```bash
# Setup
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run
streamlit run app.py

# Rebuild database
rm -rf chroma_db/
streamlit run app.py  # Will auto-rebuild

# Docker
docker build -t lolqa .
docker run -p 8501:8501 --env-file .env lolqa

# Git
git add .
git commit -m "Your message"
git push origin branch-name
```

---

## ğŸ¯ Summary

**LOLQA** is a production-ready RAG application that demonstrates:
- âœ… Modern LLM application architecture
- âœ… Intelligent tool calling with ReAct pattern
- âœ… Conversation memory and context awareness
- âœ… Hallucination prevention through strict prompting
- âœ… Data collection from multiple sources
- âœ… Vector database for semantic search
- âœ… Workflow orchestration with LangGraph
- âœ… Monitoring and observability with LangSmith

**Tech Stack**: LangChain + LangGraph + OpenAI + ChromaDB + Streamlit

**Data**: 172 League of Legends champions from Data Dragon API v15.24.1

**Deployment**: Docker, Streamlit Cloud, Railway, Render, Heroku

---

Made with âš”ï¸ for League of Legends fans!

